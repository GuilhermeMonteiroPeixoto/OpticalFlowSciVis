# python3 read_data.py --dataset=pipedcylinder2d

from lzma import FILTER_DELTA
from optparse import Values
from tkinter import X
from xml.sax import default_parser_list
from cv2 import detail_AffineBasedEstimator
# import xarray as xr
from netCDF4 import Dataset
import numpy as np
import matplotlib.pyplot as plt
# from mpl_toolkits.mplot3d import Axes3D
# from mpl_toolkits.basemap import Basemap
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
import time
from progress.bar import Bar
import pickle
import re
import pandas as pd
import csv
import argparse

from skimage.transform import rescale, resize, downscale_local_mean

def getListOfFiles(dirName):
    # For the given path, get the List of all files in the directory tree 

    # create a list of file and sub directories 
    # names in the given directory 
    listOfFile = os.listdir(dirName)
    allFiles = list()
    # Iterate over all the entries
    for entry in listOfFile:
        # Create full path
        fullPath = os.path.join(dirName, entry)
        # If entry is a directory then get the list of files in this directory 
        if os.path.isdir(fullPath):
            allFiles = allFiles + getListOfFiles(fullPath)
        else:
            allFiles.append(fullPath)
                
    return allFiles  

def visualize_series(data_to_vis, dir_res="Results", title="Data", show=True, save=False):
    fig=plt.figure()
    columns = 5
    rows = 8
    for i in range(1, columns*rows+1 ):
        if (i == data_to_vis.shape[0]):
            break
        img = data_to_vis[i]
        fig.add_subplot(rows, columns, i)
        plt.axis('off')
        plt.imshow(img, cmap='viridis')
        
    fig = plt.gcf()
    plt.suptitle(title) 
    fig.set_size_inches(12, 9)
    if show:
        plt.show()  
    if save:
        title += ".pdf"
        fig.savefig(os.path.join(dir_res, title), dpi = 200)

# Datasets:

# 2D Droplet + 20K not enought? load more + 50K train
# 2D Unsteady Fluid Simulation Ensemble for Machine Learning + 512 x 512 x 1001 x 8000 train
# 2D Unsteady Cylinder Flow with von Karman Vortex Street + 640 x 80 x 1501 inference, test generalizability
# 2D Unsteady Cylinder Flow Around Corners +  450 x 150 x 1501 inference, test generalizability

# 3D Steady Cloud-topped Boundary Layer +- 384 x 384 x 130 inference, test generalizability
# 3D Unsteady Research Vessel Tangaroa +- 300 x 180 x 120 x 201 train/inference, test generalizability
# 3D Steady Tornado (Synthetic) +- 128 x 128 x 128 inference, test generalizability
# 3D Droplet +- train  1000 in total, first 500 should be used
# generated by the Institute of Aerospace Thermodynamics in Stuttgart
# a uniform resolution of 256x256x256 in Byte resolution (0 means air, 255 denotes fluid, there is not much in-between; it stems from a two-phase flow simulation). 
# Each time step is is stored in one raw file in the order of (x,y,z), i.e, the first 256 elements depict the first row (the x-dimension), 
# and the first 256*256 elements describe the first x-y slice.

parser = argparse.ArgumentParser()
parser.add_argument('--dataset', dest='dataset', type=str, default=None)
args = parser.parse_args()
assert (not args.dataset is None)

# filename = "FluidSimML.csv" "tornado3d.nc" # "pipedcylinder2d.nc" # "cylinder2d_nc/cylinder2d.nc"
filename = args.dataset + ".nc"
# print(filename)
# filename = "cylinder2d_nc/cylinder2d.nc" # 'pipedcylinder2d.nc'

dataset = args.dataset
if dataset == "droplet3d":
    dirName = 'drop3D'
    start_time = time.time()

     # Get the list of all files in directory tree at given path
    listOfFiles = getListOfFiles(dirName)
    listOfFiles.sort()
    print("listOfFiles is sorted!")
    for k in range(10):
        print(listOfFiles[k])
    # input("input: ")

    data = []
    # data = []
    # print(data.size)
    count = 0
    dims = 256 * 256 * 256

    # Print the files
    with Bar("Loading the data...", max=len(listOfFiles) ) as bar:
        for elem in listOfFiles:
            # if elem.endswith(('.bna')):

            tmp_data = np.fromfile(elem, dtype='uint8')
            # print(tmp_data.shape)
            # input("x")
            tmp_data.resize(256, 256, 256)
            # print(tmp_data.shape)
            # input("x")

            data.append(tmp_data)

            # tmp_data = np.flip(tmp_data, 1)
            # data = np.concatenate((data, tmp_data), axis=0)

            count += 1
            if (count==601): # 
                break
            bar.next()

    #print(data)
    #print(tmp_data)
    #print(tmp_data.shape)
    #print(data.size)
    data = np.array(data)
    print('data shape:', data.shape)
    print(count)
    print(type(data[0,0,0,0]))
    # input("x")

    elapsed_time = time.time() - start_time
    print("All", count, "frames were loaded successfully in", "{0:.2f}".format(round(elapsed_time, 2)), "seconds.")

    data = data[100:]
    print('data shape:', data.shape)

    for i in range(2):
        # downsample
        data_down = []
        for i in range(data.shape[0]):
                data_down.append(downscale_local_mean(data[i,...], (2, 2, 2)))
        data_down = np.array(data_down)
        print(data_down.shape)
        # print(type(data[0,0,0,0]))
        # input("x")
        data = data_down
    print("downsampled:", data.shape)

    # prepare the data
    data = np.expand_dims(data, axis=1)
    # data = data / 255.
    data_train = data[:408] # data[:150]
    data_val = data[411:501] # data[150:201]

    data_train_tree = []
    # data_train = np.array(data_train)c
    for i in range(0, data_train.shape[0], 3): 
        data_train_tree.append(np.concatenate((data_train[i], data_train[i+2], data_train[i+1]), axis=0)) # img0, img1, gt
        # data_train_tree.append(np.concatenate(downscale_local_mean(data_train[i], (2,2,2)), 
        # downscale_local_mean(data_train[i+2], (2,2,2)), downscale_local_mean(data_train[i+1], (2,2,2)), axis=0)) # img0, img1, gt
    data_train = np.array(data_train_tree)
    print("data_train in three:", data_train.shape)
    # input("x")

    data_val_tree = []
    # data_train = np.array(data_train)
    for i in range(0, data_val.shape[0], 3): 
        data_val_tree.append(np.concatenate((data_val[i], data_val[i+2], data_val[i+1]), axis=0)) # img0, img1, gt
    data_val = np.array(data_val_tree)
    print("data_val in three:", data_val.shape)

    pkl_filename_train = "droplet3d_64_train.pkl"
    pkl_filename_val = "droplet3d_64_val.pkl"
    
    pkl_file = open(pkl_filename_train, 'wb')
    pickle.dump(data_train, pkl_file, protocol=4)
    pkl_file.close
    pkl_file = open(pkl_filename_val, 'wb')
    pickle.dump(data_val, pkl_file, protocol=4)
    pkl_file.close

    pkl_file = open(pkl_filename_train, 'rb')
    data = []
    data = pickle.load(pkl_file)

    data = np.array(data)
    print(data.shape)
    input("Done.")

elif dataset == "fluidsimml":
    print("FluidSimML dataset")
    """
    pkl_file = open(filename, 'rb')
    data = []
    data = pickle.load(pkl_file)
    print(data.shape)

    # downsample
    data_down = []
    for i in range(data.shape[0]):
            data_down.append(downscale_local_mean(data[i,...], (2, 2)))
    data_down = np.array(data_down)
    print("downsampled:", data_down.shape)
    input("x")
    data = data_down

    pkl_filename = "../Datasets/FluidSimML/FluidSimML_1000_downs.pkl" # "FluidSimML_1000.pkl"
    pkl_file = open(pkl_filename, 'wb')
    pickle.dump(data, pkl_file, protocol=4)
    pkl_file.close
    print("saved to pkl")
    input("x")
    """

    filename = "FluidSimML.csv"
    # df = pd.read_csv(filename, sep=" ", lineterminator="\n")
    # print("read from csv")

    pkl_filename = "FluidSimML/FluidSimML.pkl"
    # print(df[0:5])
    # df.to_pickle("FluidSimML.pkl")  
    # print("saved to pkl")

    arr = pd.read_pickle(pkl_filename) 
    arr = np.array(arr)
    print(arr.shape)

    # # arr = arr.dropna(axis=1, how='all')
    # # arr = arr[~np.isnan(arr)]
    # arr = arr[:,:-1]
    # print(arr.shape)
    # # print(arr)
    # print(arr[0:5]) 

    # pkl_file = open(pkl_filename, 'wb')
    # pickle.dump(arr, pkl_file, protocol=4)
    # pkl_file.close
    # print("saved to pkl")

    # arr = arr.reshape(1001, 512, 512)

    steps = 5
    start = 0 # 700
    end_total = 1000 # 900
    delta = end_total / steps
    for s in range(steps):
        start = int(delta * s)
        end = int(start + delta)
        print(start, end)

        # get magnitude of velocity vectors
        uv = []
        flow_u_i = []
        flow_v_i = []
        uv_flow = []

        # for i in range(arr.shape[0]):
        for i in range(512*512*start, 512*512*end):
            # print(i/(512*512), " / ", end/(512*512))
            u_i = np.float16(arr[i, 0])
            v_i = np.float16(arr[i, 1])
            # print(type(u_i))
            uv.append(np.sqrt(u_i * u_i + v_i * v_i))
            flow_u_i.append(u_i)
            flow_v_i.append(v_i)
        # del arr
        uv = np.asarray(uv)
        uv = uv.reshape(end-start, 512, 512)
        print("uv:", uv.shape)
        data = uv
        del uv

        flow_u_i = np.asarray(flow_u_i)
        flow_v_i = np.asarray(flow_v_i)
        flow_u_i = flow_u_i.reshape(end-start, 512, 512)
        flow_v_i = flow_v_i.reshape(end-start, 512, 512)
        uv_flow = np.hstack((flow_u_i[:, np.newaxis, ...], flow_v_i[:, np.newaxis, ...]))
        uv_flow = np.asarray(uv_flow)
        print("uv_flow:", uv_flow.shape)
        data_flow = uv_flow
        # print(type(data_flow[0,0,0,0]))
        del flow_u_i, flow_v_i, uv_flow
        # input("x")

        # downsample
        data_down = []
        flow_down = []
        for i in range(data.shape[0]):
                data_down.append(downscale_local_mean(data[i,...], (2, 2)))
                for j in range(2):
                    flow_down.append(downscale_local_mean(data_flow[i,j,...], (2, 2)))
        data_down = np.array(data_down)
        flow_down = np.array(flow_down)
        print("downsampled data:", data_down.shape)
        print("downsampled flow:", flow_down.shape)
        del data, data_flow
        # input("x")

        pkl_filename = "FluidSimML_1000_downs_data" + "_" + str(s) + ".pkl" # "FluidSimML_1000.pkl"
        pkl_file = open(pkl_filename, 'wb')
        pickle.dump(data_down, pkl_file, protocol=4)
        pkl_file.close
        print("saved data to pkl")

        pkl_flow_filename = "FluidSimML_1000_downs_flow" + "_" + str(s) + ".pkl"
        pkl_file = open(pkl_flow_filename, 'wb')
        pickle.dump(flow_down, pkl_file, protocol=4)
        pkl_file.close
        print("saved flow to pkl")

    data = []
    flow = []
    for s in range(steps):
        pkl_filename = "FluidSimML_1000_downs_data" + "_" + str(s) + ".pkl" # "FluidSimML_1000.pkl"
        with open(pkl_filename, 'rb') as pkl_file:
            data.extend(pickle.load(pkl_file))
        pkl_flow_filename = "FluidSimML_1000_downs_flow" + "_" + str(s) + ".pkl" # "FluidSimML_1000.pkl"
        with open(pkl_flow_filename, 'rb') as pkl_file:
            flow.extend(pickle.load(pkl_file))
    data = np.array(data)
    # print(data[0,0,0,0])
    flow = np.array(flow)
    print(data.shape)
    print(flow.shape)
    data_down = data
    flow_down = flow

    flow_down = flow_down[:, np.newaxis, ...]
    data_flow = np.hstack((flow_down[:1000], flow_down[1000:]))
    print(data_flow.shape)
    flow_down = data_flow

    pkl_filename = "FluidSimML/FluidSimML_1000_downs_data.pkl" # "FluidSimML_1000.pkl"
    pkl_file = open(pkl_filename, 'wb')
    pickle.dump(data_down, pkl_file, protocol=4)
    pkl_file.close
    print("saved data to pkl")

    pkl_flow_filename = "FluidSimML/FluidSimML_1000_downs_flow.pkl"
    pkl_file = open(pkl_flow_filename, 'wb')
    pickle.dump(flow_down, pkl_file, protocol=4)
    pkl_file.close
    print("saved flow to pkl")

    # visualize_series(data_down, dir_res="Results", title="FluidSimML_mag", show=False, save=True)
    # visualize_series(flow_down, dir_res="Results", title="FluidSimML_flow", show=False, save=True)

elif "2d" in filename:
    # 2D NetCDF data format
    
    fh = Dataset(filename, mode='r')
    print(fh)
    # input("x")

    title = filename[:-3]
    # input("x")
    # xdim = fh.variables['xdim'][:]
    # ydim = fh.variables['ydim'][:]
    # tdim = fh.variables['tdim'][:]
    # tdim_units = fh.variables['tdim'].units
    # fh.close()

    print(fh['u'])
    u = fh['u'][:]
    print(u.shape)
    # plt.imshow(u[100,:,:]) 
    # plt.show()
    u = np.asarray(u)
    # visualize_series(u[500:], dir_res="Results", title="U", show=True, save=True)

    print(fh['v'])
    v = fh['v'][:]
    print(v.shape)
    # plt.imshow(v[100,:,:]) 
    # plt.show()
    # visualize_series(v[500:], dir_res="Results", title="V", show=True, save=True)

    # create flow field file
    flow_u = u[:, np.newaxis, ...]
    flow_v = v[:, np.newaxis, ...]
    flow_uv = np.hstack((flow_u, flow_v))
    # flow_uv = np.flip(flow_uv, 0)
    flow_uv = flow_uv[...,::-1,:] # flip vertically
    print(flow_uv.shape)
    # visualize_series(flow_uv[500:, 0], dir_res="Results", title=title+"flow_uv", show=True, save=True)

    pkl_filename = filename[:-3] + "_flow" ".pkl" 
    pkl_file = open(pkl_filename, 'wb')
    pickle.dump(flow_uv, pkl_file, protocol=4)
    pkl_file.close
    input("flow file created")

    # get magnitude of velocity vectors
    uv = []
    for i in range(u.shape[0]):
        u_i = u[i]
        v_i = v[i]
        uv.append(np.flip(np.sqrt(u_i * u_i + v_i * v_i), 0))
    uv = np.asarray(uv)
    # visualize_series(uv[500:], dir_res="Results", title=title+"UV", show=True, save=True)

    print("uv:", uv.shape)

    pkl_filename = filename[:-3] + ".pkl" 

    pkl_file = open(pkl_filename, 'wb')
    pickle.dump(uv, pkl_file, protocol=4)
    pkl_file.close
    print("Pkl file created")

    pkl_file = open(pkl_filename, 'rb')
    data = []
    data = pickle.load(pkl_file)
    pkl_file.close
    print(data.shape)

    input("stop")

    print(fh['w'])
    w = fh['w'][:]
    print(w.shape)
    # plt.imshow(w[100,:,:]) 
    # plt.show()
    visualize_series(w[500:], dir_res="Results", title=title+"W", show=True, save=True)

elif "3d.nc" in filename:
    # 3D NetCDF data format
    
    fh = Dataset(filename, mode='r')
    print(fh)
    input("x")
    
    title = filename[:-3]

    print(fh['u'])
    u = fh['u'][:]
    print(u.shape)
    # plt.imshow(u[100,:,:]) 
    # plt.show()
    u = np.asarray(u)
    # visualize_series(u[500:], dir_res="Results", title="U", show=True, save=True)

    print(fh['v'])
    v = fh['v'][:]
    print(v.shape)
    # plt.imshow(v[100,:,:]) 
    # plt.show()
    # visualize_series(v[500:], dir_res="Results", title="V", show=True, save=True)

    print(fh['w'])
    w = fh['w'][:]
    print(w.shape)

    # input("x")

    # get magnitude of velocity vectors
    # uv = []
    # for i in range(u.shape[0]):
    #     u_i = u[i]
    #     v_i = v[i]
    #     uv.append(np.flip(np.sqrt(u_i*u_i + v_i*v_i), 0))
    # uv = np.asarray(uv)
    # visualize_series(uv, dir_res="Results", title=title+"_UV", show=True, save=True)

    # vw = []
    # for i in range(v.shape[0]):
    #     v_i = v[i]
    #     w_i = w[i]
    #     vw.append(np.flip(np.sqrt(v_i*v_i + w_i*w_i), 0))
    # vw = np.asarray(vw)
    # visualize_series(vw, dir_res="Results", title=title+"_vw", show=True, save=True)

    # get magnitude of velocity vectors
    uvw = []
    for i in range(u.shape[0]):
        u_i = u[i]
        v_i = v[i]
        w_i = w[i]
        uvw.append(np.flip(np.sqrt(u_i * u_i + v_i * v_i + w_i * w_i), 0))
    uvw = np.asarray(uvw)
    # visualize_series(uvw[500:], dir_res="Results", title="UV", show=True, save=True)

    print("uvw:", uvw.shape)
    data = uvw

    data_down = []
    for i in range(data.shape[0]):
            data_down.append(downscale_local_mean(data[i,...], (2, 2, 2)))
    data_down = np.array(data_down)
    print(data_down.shape)
    # print(type(data[0,0,0,0]))
    # input("x")
    data = data_down
    print("downsampled:", data.shape)

    # View it.
    # from mayavi import mlab
    # s = mlab.mesh(u, v, w)
    # mlab.show()
    # mlab.savefig("Results/tprnado_3d", figure=s)

    # fig = plt.figure()
    # ax = plt.axes(projection='3d')
    # ax.contour3D(u, v, w, 50, cmap='viridis')
    # ax.set_xlabel('u')
    # ax.set_ylabel('v')
    # ax.set_zlabel('w')
    # plt.show()  
    # dir_res="Results"
    # title=title+"_uvw"
    # fig.savefig(os.path.join(dir_res, title), dpi = 200)

    pkl_filename = filename[:-3] + "_downs" + ".pkl" 

    pkl_file = open(pkl_filename, 'wb')
    pickle.dump(data, pkl_file, protocol=4)
    pkl_file.close
    print("Pkl file created")
    
    pkl_filename = filename[:-3] + ".pkl" 
    pkl_file = open(pkl_filename, 'rb')
    data = []
    data = pickle.load(pkl_file)
    pkl_file.close
    print(data.shape)
    # input("stop")

    visualize_series(data[100,...], dir_res="Results", title="Tangaroa_VW", show=True, save=True)
    # input("stop")
    

# print(type(xdim))
# print(xdim.shape)

# x = np.array(xdim)

# print(type(xdim))
# print(xdim.shape)

# x = data.xdim.values
# # print(type(x))
# # print(x[0].shape)

# # Get some parameters for the Stereographic Projection
# lon_0 = xdim.mean()
# lat_0 = ydim.mean()

# m = Basemap(width=5000000,height=3500000,
#             resolution='l',projection='stere',\
#             lat_ts=10,lat_0=lat_0,lon_0=lon_0)

# # Because our lon and lat variables are 1D,
# # use meshgrid to create 2D arrays
# # Not necessary if coordinates are already in 2D arrays.
# lon, lat = np.meshgrid(xdim, ydim)
# xi, yi = m(lon, lat)

# # Plot Data
# cs = m.pcolor(xi,yi,np.squeeze(tdim))

# Add Grid Lines
# m.drawparallels(np.arange(-80., 81., 10.), labels=[1,0,0,0], fontsize=10)
# m.drawmeridians(np.arange(-180., 181., 10.), labels=[0,0,0,1], fontsize=10)

# Add Coastlines, States, and Country Boundaries
# m.drawcoastlines()
# m.drawstates()
# m.drawcountries()

# Add Colorbar
# cbar = m.colorbar(cs, location='bottom', pad="10%")
# cbar.set_label(tdim_units)

# Add Title
# plt.title('DJF Maximum Temperature')

# plt.show()


# filename = 'drop3D/funs00280'

# data = open(filename, encoding= 'unicode_escape')
# data = data.read()
# print(len(data))
"""
dim_size = 256
data = np.zeros((0, dim_size, dim_size, dim_size))

dirName = 'drop3D'

# Get the list of all files in directory tree at given path
listOfFiles = getListOfFiles(dirName)
listOfFiles.sort()
print("listOfFiles is sorted!")
for k in range(30):
    print(listOfFiles[k])
# input("waiting...")

count = 0
maxNumImages = 20
with Bar("Loading the data...", max=maxNumImages) as bar:
    for elem in listOfFiles: 
        if re.search("(10[0-9]|11[0-9])$", elem):
            print(elem)
            tmp_data = np.fromfile(elem, dtype='uint8')
            tmp_data.resize(1, dim_size, dim_size, dim_size)
            data = np.append(data, tmp_data, axis=0)
            count += 1
            if (count==maxNumImages): # load a subset of the dataset
                break
            bar.next()
        
print(data.shape)
input("")

pkl_file = open("drop3D_data.pkl", 'wb')
pickle.dump(data, pkl_file)
pkl_file.close

pkl_file = open("drop3D_data.pkl", 'rb')
data = []
data = pickle.load(pkl_file)
pkl_file.close

print(data.shape)

x = np.squeeze(data[0,:,0,0])
y = np.squeeze(data[0,0,:,0])
z = np.squeeze(data[0,0,0,:])

# from mayavi import mlab
# s = mlab.mesh(x, y, z)
# mlab.show()

fig = plt.figure()
ax = fig.gca(projection='3d')
ax.plot(x, y, z, label='drop')
plt.show()
"""

# filename = 'pipedcylinder2d.nc'
# Dimensions:  (tdim: 1501, ydim: 150, xdim: 450, const: 1)
# Coordinates:
#   * xdim     (xdim) float32 -0.5 -0.4866 -0.4733 -0.4599 ... 5.473 5.487 5.5
#   * ydim     (ydim) float32 -0.5 -0.4866 -0.4732 -0.4597 ... 1.473 1.487 1.5
#   * tdim     (tdim) float32 0.0 0.01 0.02 0.03 0.04 ... 14.97 14.98 14.99 15.0
# Dimensions without coordinates: const
# Data variables:
#     u        (tdim, ydim, xdim) float32 ...
#     v        (tdim, ydim, xdim) float32 ...
#     nu       (const) float32 ... ? kinematic viscosity
#     radius   (const) float32 ...
#     Re       (const) float32 ...
# Regular grid resolution (X x Y x T): 450 x 150 x 1501
# Simulation domain: [-0.5, 5.5] x [-0.5, 1.5] x [0, 15]
# Reynolds Number: 160 
# Kinematic viscosity: 0.00078125
# Obstacles at (0,0) and (3,1) both with radius: 0.0625 

# dimensions(sizes): xdim(450), ydim(150), tdim(1501), const(1)
# variables(dimensions): float32 u(tdim, ydim, xdim), float32 v(tdim, ydim, xdim), float32 xdim(xdim), float32 ydim(ydim), float32 tdim(tdim), float32 nu(const), float32 radius(const), float32 Re(const)


# filename = 'ctbl3d.nc'
# Dimensions:  (zdim: 130, ydim: 384, xdim: 384)
# Coordinates:
#   * xdim     (xdim) float32 0.0 0.02611 0.05222 0.07833 ... 9.948 9.974 10.0
#   * ydim     (ydim) float32 0.0 0.02611 0.05222 0.07833 ... 9.948 9.974 10.0
#   * zdim     (zdim) float32 0.0 0.02481 0.04961 0.07442 ... 3.126 3.15 3.175 3.2
# Data variables:
#     u        (zdim, ydim, xdim) float32 ...
#     v        (zdim, ydim, xdim) float32 ...
#     w        (zdim, ydim, xdim) float32 ...
# acknowledgement: German Climate Computing Center (DKRZ) and Max-Planck Institute for Meteorology (MPI-M). Simulated within the HD(CP)² project.
# dimensions(sizes): xdim(384), ydim(384), zdim(130), const(1)
# variables(dimensions): float32 u(zdim, ydim, xdim), float32 v(zdim, ydim, xdim), float32 w(zdim, ydim, xdim), float32 xdim(xdim), float32 ydim(ydim), float32 zdim(zdim)


# data = xr.open_dataset(filename)
# print(data)                         # show all variables inside this dataset
# print(data.temperature.values)      # this is a 180x201x360 numpy array
# print(data.r)                       # radial discretization

# print(data.vx) 
# print(data.vy) 
# print(data.vz) 
# print("u: ", data.u.shape) 
# print("v: ", data.v.shape) 
# print("w: ", data.w.shape) 

# x = data.xdim.values
# print(x) 
# for t in range ()

# filename = "cylinder2d_nc/cylinder2d.nc" # 'pipedcylinder2d.nc'
# variables(dimensions): float32 u(tdim, ydim, xdim), float32 v(tdim, ydim, xdim), float32 xdim(xdim), float32 ydim(ydim), float32 tdim(tdim), float32 nu(const), float32 radius(const), float32 Re(const)

